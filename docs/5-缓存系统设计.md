# PanSou 缓存系统设计详解

## 1. 缓存系统概述

缓存系统是PanSou性能优化的核心组件，通过增强版两级缓存（内存+分片磁盘）机制，大幅提升重复查询的响应速度。该系统采用分层设计，实现了高效的缓存存取和智能的缓存策略。

PanSou的缓存系统包括两个主要部分：
1. **通用缓存系统**：用于API响应和常规搜索结果缓存
2. **异步插件缓存系统**：专为异步插件设计的高级缓存机制

### 1.1 设计思想概述

PanSou缓存系统的设计基于以下核心理念：

1. **性能与新鲜度平衡**：在高性能和数据新鲜度之间寻求最佳平衡点
2. **分层缓存策略**：采用多层次缓存架构，满足不同场景的需求
3. **协同工作机制**：主缓存系统与异步插件缓存系统协同工作
4. **自适应优化**：根据访问模式和数据特性自动调整缓存策略
5. **资源高效利用**：智能管理内存和磁盘资源，避免浪费

### 1.2 目录结构

```
pansou/util/cache/
├── cache_key.go       # 优化的缓存键生成
├── memory_cache.go    # 原始内存缓存实现
├── sharded_memory_cache.go # 分片内存缓存
├── disk_cache.go      # 磁盘缓存实现
├── sharded_disk_cache.go # 分片磁盘缓存
├── enhanced_two_level_cache.go # 增强版两级缓存实现
├── serializer.go      # 序列化器接口
└── utils.go           # 缓存工具函数

pansou/plugin/
├── baseasyncplugin.go # 异步插件缓存实现

pansou/util/json/
└── json.go            # 基于sonic的高性能JSON处理封装
```

## 2. 缓存架构设计

### 2.1 增强版两级缓存架构

PanSou采用增强版两级缓存架构，包括分片内存缓存和分片磁盘缓存：

```
┌─────────────────────────┐
│      搜索请求            │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     缓存键生成           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│   分片内存缓存查询        │
│  (基于哈希分片分布)        │
└───────────┬─────────────┘
            │ (未命中)
┌───────────▼─────────────┐
│  分片磁盘缓存查询         │
│  (动态分片数，位运算)       │
└───────────┬─────────────┘
            │ (未命中)
┌───────────▼─────────────┐
│     执行搜索             │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│   更新分片内存缓存        │
│  (原子操作优化)           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│ 异步更新分片磁盘缓存       │
│  (并行分片写入)           │
└─────────────────────────┘
```

### 2.2 缓存层次职责

1. **分片内存缓存 (ShardedMemoryCache)**：
   - 基于CPU核心数动态分片（2×核心数，最少4，最多64）
   - 每个分片独立的sync.RWMutex，避免锁竞争
   - 原子操作优化lastUsed时间戳更新
   - 位运算哈希分片分布，提供快速访问
   - 存储热点数据，减少磁盘I/O
   - 并行分片清理机制

2. **分片磁盘缓存 (OptimizedShardedDiskCache)**：
   - 动态分片数量（基于CPU核心数，最多32个分片）
   - 位运算哈希算法优化分片路由性能
   - 分片数为2的幂，确保位运算掩码高效
   - 提供持久存储，在服务重启后保留缓存
   - 并行分片I/O操作，减少磁盘访问瓶颈
   - 独立分片锁机制，提高并发写入性能

3. **缓存协同机制**：
   - 内存缓存同步更新，磁盘缓存异步更新
   - 缓存注入机制：主缓存的Set方法注入到异步插件
   - 分片策略一致性：内存和磁盘使用相同的哈希算法
   - 智能缓存回写：内存命中时更新磁盘缓存时间戳

### 2.3 为什么选择两级缓存架构？

#### 2.3.1 传统单级缓存的局限性

传统的单级缓存（如纯内存缓存或纯磁盘缓存）存在以下局限性：

1. **纯内存缓存**：
   - 容量受限于可用内存
   - 服务重启后缓存丢失
   - 内存资源昂贵

2. **纯磁盘缓存**：
   - 访问速度较慢
   - I/O操作可能成为瓶颈
   - 高并发场景下性能下降

#### 2.3.2 两级缓存的优势

PanSou采用的增强版两级缓存架构结合了内存缓存和磁盘缓存的优势：

1. **内存缓存层**：
   - 提供极速访问
   - 减少磁盘I/O操作
   - 缓存热点数据

2. **磁盘缓存层**：
   - 提供持久存储
   - 支持更大的缓存容量
   - 服务重启后缓存依然有效

3. **协同工作**：
   - 内存缓存作为磁盘缓存的"加速层"
   - 磁盘缓存作为内存缓存的"持久层"
   - 两层缓存互相补充，形成完整的缓存体系

### 2.4 异步插件缓存系统架构

异步插件缓存系统实现了"尽快响应，持续处理"的异步模式：

```
┌─────────────────────────┐
│      搜索请求            │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     缓存键生成           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     缓存检查             │
└───────────┬─────────────┘
            │ (未命中)
┌───────────┬─────────────┐
│ 快速响应通道│  后台处理通道 │
└───────┬───┴─────────┬───┘
        │             │
┌───────▼───────┐ ┌───▼───────────┐
│ 响应超时返回    │ │  完整处理      │
└───────┬───────┘ └───┬───────────┘
        │             │
┌───────▼───────┐ ┌───▼───────────┐
│ 返回部分结果    │ │ 更新插件缓存    │
└───────────────┘ └───┬───────────┘
                      │
                  ┌───▼───────────┐
                  │ 更新主缓存      │
                  └───────────────┘
``` 

## 3. 核心组件与数据结构

### 3.1 核心组件概览

PanSou缓存系统由以下核心组件组成：

1. **EnhancedTwoLevelCache**：增强版两级缓存，整合内存缓存和分片磁盘缓存
2. **MemoryCache**：内存缓存，提供快速访问
3. **ShardedDiskCache**：分片磁盘缓存，提供持久存储
4. **DiskCache**：单个磁盘缓存分片
5. **Serializer**：序列化器接口及其实现
6. **BaseAsyncPlugin**：异步插件基类，实现异步搜索和缓存更新

这些组件通过精心设计的接口和协作机制，共同构成了PanSou的高性能缓存系统。

### 3.2 数据结构设计

#### 3.2.1 增强版两级缓存

```go
// EnhancedTwoLevelCache 增强版两级缓存
type EnhancedTwoLevelCache struct {
    memory     *ShardedMemoryCache    // 分片内存缓存
    disk       *ShardedDiskCache      // 分片磁盘缓存
    mutex      sync.RWMutex           // 读写锁
    serializer Serializer             // 序列化器
}
```

增强版两级缓存是整个缓存系统的核心，它整合了内存缓存和分片磁盘缓存，提供了统一的缓存接口。

#### 3.2.2 分片内存缓存

```go
// 分片内存缓存
type ShardedMemoryCache struct {
    shards    []*memoryCacheShard  // 分片数组
    shardMask uint32               // 分片掩码（用于快速取模）
    maxItems  int                  // 最大项目数
    maxSize   int64                // 最大内存使用量
    itemsPerShard int              // 每个分片的最大项目数
    sizePerShard  int64            // 每个分片的最大内存使用量
}

// 单个分片
type memoryCacheShard struct {
    items    map[string]*shardedMemoryCacheItem
    mutex    sync.RWMutex          // 分片级读写锁
    currSize int64                 // 当前分片内存使用量
}

// 分片内存缓存项
type shardedMemoryCacheItem struct {
    data         []byte      // 缓存数据
    expiry       time.Time   // 过期时间
    lastUsed     int64       // 最后使用时间（原子操作）
    lastModified time.Time   // 最后修改时间
    size         int         // 数据大小
}
```

分片内存缓存使用动态分片数量（基于CPU核心数×2），每个分片独立使用sync.RWMutex，避免全局锁竞争。关键优化包括：
- **原子操作**：lastUsed时间戳使用atomic.StoreInt64避免锁开销
- **位运算哈希**：使用hash & shardMask快速确定分片索引
- **并行清理**：每个分片独立进行过期清理
- **LRU淘汰**：基于原子操作的lastUsed实现高效LRU淘汰策略

#### 3.2.3 分片磁盘缓存

```go
// ShardedDiskCache 分片磁盘缓存（优化版）
type ShardedDiskCache struct {
    baseDir     string          // 基础目录
    shardCount  int             // 动态分片数量
    shardMask   uint32          // 分片掩码（用于快速取模）
    shards      []*DiskCache    // 分片数组
    maxSizeMB   int             // 最大磁盘使用量
    mutex       sync.RWMutex    // 读写锁
}
```

分片磁盘缓存通过动态分片数量和位运算哈希算法优化并发性能：
- **动态分片数**：基于CPU核心数×2计算，最多32个分片，确保分片数为2的幂
- **位运算哈希**：使用`hash & shardMask`替代`hash % shardCount`，提升路由性能
- **并行I/O**：每个分片独立进行磁盘读写操作，减少I/O阻塞
- **均匀分布**：通过FNV-1a哈希算法确保缓存键在各分片间均匀分布
- **独立清理**：各分片并行执行过期数据清理，提高清理效率

#### 3.2.4 磁盘缓存

```go
// 磁盘缓存项元数据
type diskCacheMetadata struct {
    Key           string    `json:"key"`           // 缓存键
    Expiry        time.Time `json:"expiry"`        // 过期时间
    LastUsed      time.Time `json:"last_used"`     // 最后使用时间
    Size          int       `json:"size"`          // 数据大小
    LastModified  time.Time `json:"last_modified"` // 最后修改时间
}

// DiskCache 磁盘缓存
type DiskCache struct {
    path      string                          // 缓存路径
    maxSizeMB int                             // 最大磁盘使用量
    metadata  map[string]*diskCacheMetadata   // 元数据映射
    mutex     sync.RWMutex                    // 读写锁
    currSize  int64                           // 当前磁盘使用量
}
```

磁盘缓存负责将缓存数据持久化到磁盘，并维护缓存项的元数据。它实现了基于访问时间的淘汰策略，当磁盘使用量超过限制时，会淘汰最久未使用的项。

#### 3.2.5 序列化器

```go
// Serializer 序列化接口
type Serializer interface {
    Serialize(v interface{}) ([]byte, error)
    Deserialize(data []byte, v interface{}) error
}

// GobSerializer 使用gob进行序列化/反序列化
type GobSerializer struct {
    bufferPool sync.Pool
}

// JSONSerializer 使用JSON进行序列化/反序列化
type JSONSerializer struct {
    // 使用sonic库优化性能
}
```

序列化器负责将数据结构转换为字节数组，以便存储到缓存中。PanSou实现了两种序列化器：GobSerializer和JSONSerializer，前者性能更高，后者兼容性更好。

#### 3.2.6 异步插件缓存

```go
// 缓存相关变量
var (
    // API响应缓存，键为关键词，值为缓存的响应
    apiResponseCache = sync.Map{}
    
    // 最后一次清理缓存的时间
    lastCacheCleanTime = time.Now()
    
    // 最后一次保存缓存的时间
    lastCacheSaveTime = time.Now()
    
    // 缓存保存锁，防止并发保存导致的竞态条件
    saveCacheLock     sync.Mutex
    
    // 工作池相关变量
    backgroundWorkerPool chan struct{}
    backgroundTasksCount int32 = 0
)

// 缓存响应结构
type cachedResponse struct {
    Results     []model.SearchResult `json:"results"`     // 搜索结果
    Timestamp   time.Time            `json:"timestamp"`   // 缓存时间
    Complete    bool                 `json:"complete"`    // 是否完整
    LastAccess  time.Time            `json:"last_access"` // 最后访问时间
    AccessCount int                  `json:"access_count"`// 访问计数
}

// BaseAsyncPlugin 基础异步插件结构
type BaseAsyncPlugin struct {
    name              string                                    // 插件名称
    priority          int                                       // 优先级
    client            *http.Client                              // 短超时客户端
    backgroundClient  *http.Client                              // 长超时客户端
    cacheTTL          time.Duration                             // 缓存有效期
    mainCacheUpdater  func(string, []byte, time.Duration) error // 主缓存更新函数
    MainCacheKey      string                                    // 主缓存键，导出字段，由主程序设置
}
```

异步插件缓存是为异步插件设计的专用缓存系统，它实现了"尽快响应，持续处理"的异步模式。通过`mainCacheUpdater`函数，异步插件可以直接更新主缓存系统，确保缓存一致性。主程序通过`SetMainCacheKey`方法将缓存键传递给插件并存储在`MainCacheKey`字段中，插件直接使用这个字段而不再重新生成缓存键，避免了缓存键不一致的问题。

### 3.3 分片策略设计

#### 3.3.1 为什么需要分片？

在高并发场景下，传统的单一磁盘缓存存在以下问题：

1. **锁竞争**：多线程并发访问同一资源导致严重的锁竞争
2. **I/O瓶颈**：单一文件系统目录下大量小文件导致I/O性能下降
3. **扩展性限制**：难以横向扩展以支持更高的并发访问

#### 3.3.2 分片实现原理

分片磁盘缓存的核心是通过哈希算法将缓存键映射到不同的分片：

```go
// 获取键对应的分片
func (c *ShardedDiskCache) getShard(key string) *DiskCache {
    // 计算哈希值决定分片
    h := fnv.New32a()
    h.Write([]byte(key))
    shardIndex := int(h.Sum32()) % c.shardCount
    return c.shards[shardIndex]
}
```

这种设计确保：

1. **确定性映射**：相同的键总是映射到相同的分片
2. **均匀分布**：缓存键均匀分布到各个分片
3. **隔离故障**：单个分片的问题不会影响其他分片

### 3.4 并发控制与竞态条件处理

#### 3.4.1 互斥锁保护缓存保存

为了防止多个goroutine同时保存缓存导致的竞态条件，系统使用互斥锁保护`saveCacheToDisk`函数：

```go
// 缓存保存锁，防止并发保存导致的竞态条件
saveCacheLock sync.Mutex

// saveCacheToDisk 将缓存保存到磁盘
func saveCacheToDisk() {
    // 使用互斥锁确保同一时间只有一个goroutine可以执行
    saveCacheLock.Lock()
    defer saveCacheLock.Unlock()
    
    // ... 缓存保存逻辑 ...
}
```

这种设计确保：
1. 同一时间只有一个goroutine可以执行缓存保存操作
2. 避免多个goroutine同时创建和重命名临时文件导致的冲突
3. 防止缓存文件损坏或不一致

#### 3.4.2 随机延迟减少冲突

在后台刷新缓存时，系统添加了随机延迟，进一步减少并发冲突的可能性：

```go
// refreshCacheInBackground 在后台刷新缓存
func (p *BaseAsyncPlugin) refreshCacheInBackground(...) {
    // ... 缓存刷新逻辑 ...
    
    // 添加随机延迟，避免多个goroutine同时调用saveCacheToDisk
    time.Sleep(time.Duration(100+rand.Intn(500)) * time.Millisecond)
    
    // 更新缓存后立即触发保存
    go saveCacheToDisk()
}
```

这种随机延迟机制可以：
1. 错开多个goroutine的缓存保存时间
2. 减少对互斥锁的竞争
3. 提高系统在高并发场景下的稳定性

#### 3.4.3 sync.Map的无锁设计

异步插件缓存使用`sync.Map`存储缓存项，而不是普通的map加锁：

```go
// API响应缓存，键为关键词，值为缓存的响应
apiResponseCache = sync.Map{}
```

`sync.Map`的优势：
1. 针对读多写少的场景优化
2. 无需显式加锁，减少锁竞争
3. 支持并发读取和更新操作

### 3.5 关键数据流转

#### 3.5.1 缓存写入流程

```
┌─────────────────────────┐
│     搜索结果生成          │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     序列化数据           │
└───────────┬─────────────┘
            │
┌───────────┬──────────────┐
│ 更新内存缓存│异步更新磁盘缓存│
└───────────┴──────────────┘
```

1. **搜索结果生成**：系统生成搜索结果
2. **序列化数据**：使用序列化器将结果转换为字节数组
3. **更新内存缓存**：立即更新内存缓存
4. **异步更新磁盘缓存**：在后台异步更新磁盘缓存，不阻塞主流程

#### 3.5.2 缓存读取流程

```
┌─────────────────────────┐
│     缓存键生成           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  检查内存缓存             │
└───────────┬─────────────┘
            │ (未命中)
┌───────────▼─────────────┐
│  使用磁盘数据更新内存      │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  反序列化数据             │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  返回缓存结果             │
└─────────────────────────┘
```

1. **缓存键生成**：根据搜索参数生成缓存键
2. **检查内存缓存**：查询内存缓存是否命中，命中则直接返回缓存结果
3. **检查磁盘缓存**：查询磁盘缓存是否命中
4. **更新内存缓存**：使用磁盘数据更新内存缓存
5. **反序列化数据**：将字节数组转换回原始数据结构
6. **返回结果**：返回缓存结果

这种优化的读取流程确保了系统总是能获取到最新的缓存数据，特别适合异步插件场景。 

## 4. 缓存键设计

### 4.1 缓存键设计的挑战

缓存键设计是缓存系统的基础，但面临以下挑战：

1. **语义等价性**：不同形式但语义相同的查询应使用相同的缓存键
2. **参数敏感性**：缓存键需要包含所有影响结果的参数
3. **长度与性能**：过长的缓存键会影响性能
4. **一致性保证**：确保不同组件生成相同格式的缓存键

### 4.2 分离的缓存键生成

PanSou实现了分离的缓存键生成策略，为TG搜索和插件搜索生成独立的缓存键。

```go
// GenerateTGCacheKey 为TG搜索生成缓存键
func GenerateTGCacheKey(keyword string, channels []string) string {
    // 关键词标准化
    normalizedKeyword := strings.ToLower(strings.TrimSpace(keyword))
    
    // 获取频道列表哈希
    channelsHash := getChannelsHash(channels)
    
    // 生成TG搜索特定的缓存键
    keyStr := fmt.Sprintf("tg:%s:%s", normalizedKeyword, channelsHash)
    hash := md5.Sum([]byte(keyStr))
    return hex.EncodeToString(hash[:])
}

// GeneratePluginCacheKey 为插件搜索生成缓存键
func GeneratePluginCacheKey(keyword string, plugins []string) string {
    // 关键词标准化
    normalizedKeyword := strings.ToLower(strings.TrimSpace(keyword))
    
    // 获取插件列表哈希
    pluginsHash := getPluginsHash(plugins)
    
    // 生成插件搜索特定的缓存键
    keyStr := fmt.Sprintf("plugin:%s:%s", normalizedKeyword, pluginsHash)
    hash := md5.Sum([]byte(keyStr))
    return hex.EncodeToString(hash[:])
}
```

### 4.3 缓存键设计策略

PanSou采用了以下缓存键设计策略：

1. **参数标准化**：
   - 关键词转小写并去除前后空格
   - 数组参数排序，确保顺序不同但内容相同的参数生成相同的键
   - 空参数和未指定参数的统一处理

2. **前缀区分**：
   - TG搜索使用"tg:"前缀
   - 插件搜索使用"plugin:"前缀
   - 确保不同类型的搜索使用不同的缓存空间

3. **哈希处理**：
   - 对完整的键字符串进行MD5哈希
   - 减小缓存键长度
   - 提高查找效率

4. **统一格式**：
   - 异步插件和主缓存系统使用相同格式的缓存键
   - 确保缓存一致性

5. **扩展参数处理**：
   - 扩展参数（ext）不参与缓存键生成，避免缓存爆炸问题

### 4.4 列表参数处理

```go
// 获取或计算插件哈希
func getPluginsHash(plugins []string) string {
    // 检查是否为空列表
    if plugins == nil || len(plugins) == 0 {
        // 使用预计算的所有插件哈希
        if hash, ok := precomputedHashes.Load("all_plugins"); ok {
            return hash.(string)
        }
        return allPluginsHash
    }
    
    // 检查是否有空字符串元素
    hasNonEmptyPlugin := false
    for _, p := range plugins {
        if p != "" {
            hasNonEmptyPlugin = true
            break
        }
    }
    
    // 如果全是空字符串，也视为空列表
    if !hasNonEmptyPlugin {
        if hash, ok := precomputedHashes.Load("all_plugins"); ok {
            return hash.(string)
        }
        return allPluginsHash
    }
    
    // 对于小型列表，直接使用字符串连接
    if len(plugins) < 5 {
        pluginsCopy := make([]string, 0, len(plugins))
        for _, p := range plugins {
            if p != "" { // 忽略空字符串
                pluginsCopy = append(pluginsCopy, p)
            }
        }
        sort.Strings(pluginsCopy)
        
        // 检查是否有预计算的哈希
        key := strings.Join(pluginsCopy, ",")
        if hash, ok := precomputedHashes.Load("plugins:"+key); ok {
            return hash.(string)
        }
        
        return strings.Join(pluginsCopy, ",")
    }
    
    // 生成排序后的字符串用作键，忽略空字符串
    pluginsCopy := make([]string, 0, len(plugins))
    for _, p := range plugins {
        if p != "" { // 忽略空字符串
            pluginsCopy = append(pluginsCopy, p)
        }
    }
    sort.Strings(pluginsCopy)
    key := strings.Join(pluginsCopy, ",")
    
    // 尝试从缓存获取
    if hash, ok := pluginHashCache.Load(key); ok {
        return hash.(string)
    }
    
    // 计算哈希
    hash := calculateListHash(pluginsCopy)
    
    // 存入缓存
    pluginHashCache.Store(key, hash)
    return hash
}
```

### 4.5 预计算哈希优化

```go
// 初始化预计算的哈希值
func init() {
    // 预计算空列表的哈希值
    precomputedHashes.Store("empty_channels", "all")
    
    // 预计算常用的频道组合哈希值
    commonChannels := [][]string{
        {"dongman", "anime"},
        {"movie", "film"},
        {"music", "audio"},
        {"book", "ebook"},
    }
    
    for _, channels := range commonChannels {
        key := strings.Join(channels, ",")
        hash := calculateListHash(channels)
        precomputedHashes.Store("channels:"+key, hash)
    }
    
    // 预计算常用的插件组合哈希值
    commonPlugins := [][]string{
        {"pan666", "panta"},
        {"aliyun", "baidu"},
    }
    
    for _, plugins := range commonPlugins {
        key := strings.Join(plugins, ",")
        hash := calculateListHash(plugins)
        precomputedHashes.Store("plugins:"+key, hash)
    }
    
    // 预计算所有插件的哈希值
    allPlugins := plugin.GetRegisteredPlugins()
    allPluginNames := make([]string, 0, len(allPlugins))
    for _, p := range allPlugins {
        allPluginNames = append(allPluginNames, p.Name())
    }
    sort.Strings(allPluginNames)
    allPluginsHash = calculateListHash(allPluginNames)
    precomputedHashes.Store("all_plugins", allPluginsHash)
}
```

## 5. 关键方法实现

### 5.1 增强版两级缓存实现

#### 5.1.1 创建增强版两级缓存

```go
// NewEnhancedTwoLevelCache 创建新的增强版两级缓存
func NewEnhancedTwoLevelCache() (*EnhancedTwoLevelCache, error) {
    // 内存缓存大小为磁盘缓存的60%
    memCacheMaxItems := 5000
    memCacheSizeMB := config.AppConfig.CacheMaxSizeMB * 3 / 5
    
    memCache := NewShardedMemoryCache(memCacheMaxItems, memCacheSizeMB)
    memCache.StartCleanupTask()

    // 创建优化的分片磁盘缓存，使用动态分片数量
    diskCache, err := NewOptimizedShardedDiskCache(config.AppConfig.CachePath, config.AppConfig.CacheMaxSizeMB)
    if err != nil {
        return nil, err
    }

    // 创建序列化器
    serializer := NewGobSerializer()

    return &EnhancedTwoLevelCache{
        memory:     memCache,
        disk:       diskCache,
        serializer: serializer,
    }, nil
}
```

#### 5.1.2 优化的缓存读取策略

```go
// Get 获取缓存
func (c *EnhancedTwoLevelCache) Get(key string) ([]byte, bool, error) {
	
	// 检查内存缓存
	data, _, memHit := c.memory.GetWithTimestamp(key)
	if memHit {
		return data, true, nil
	}

    // 尝试从磁盘读取数据
	diskData, diskHit, diskErr := c.disk.Get(key)
	if diskErr == nil && diskHit {
		// 磁盘缓存命中，更新内存缓存
		diskLastModified, _ := c.disk.GetLastModified(key)
		ttl := time.Duration(config.AppConfig.CacheTTLMinutes) * time.Minute
		c.memory.SetWithTimestamp(key, diskData, ttl, diskLastModified)
		return diskData, true, nil
	}
	
	return nil, false, nil
}
```

#### 5.1.3 异步缓存写入

```go
// Set 设置缓存
func (c *EnhancedTwoLevelCache) Set(key string, data []byte, ttl time.Duration) error {
    // 获取当前时间作为最后修改时间
    now := time.Now()
    
    // 先设置内存缓存（这是快速操作，直接在当前goroutine中执行）
    c.memory.SetWithTimestamp(key, data, ttl, now)
    
    // 异步设置磁盘缓存（这是IO操作，可能较慢）
    go func(k string, d []byte, t time.Duration) {
        // 使用独立的goroutine写入磁盘，避免阻塞调用者
        _ = c.disk.Set(k, d, t)
    }(key, data, ttl)
    
    return nil
}
```

#### 5.1.4 缓存删除

```go
// Delete 删除缓存
func (c *EnhancedTwoLevelCache) Delete(key string) error {
    // 从内存缓存删除
    c.memory.mutex.Lock()
    if item, exists := c.memory.items[key]; exists {
        c.memory.currSize -= int64(item.size)
        delete(c.memory.items, key)
    }
    c.memory.mutex.Unlock()
    
    // 从磁盘缓存删除
    return c.disk.Delete(key)
}
```

### 5.2 内存缓存实现

#### 5.2.1 LRU淘汰策略

```go
// 驱逐策略 - LRU
func (c *MemoryCache) evict() {
    // 找出最久未使用的项
    var oldestKey string
    var oldestTime time.Time

    // 初始化为当前时间
    oldestTime = time.Now()

    for k, v := range c.items {
        if v.lastUsed.Before(oldestTime) {
            oldestKey = k
            oldestTime = v.lastUsed
        }
    }

    // 如果找到了最久未使用的项，删除它
    if oldestKey != "" {
        item := c.items[oldestKey]
        c.currSize -= int64(item.size)
        delete(c.items, oldestKey)
    }
}
```

#### 5.2.2 带时间戳的缓存设置

```go
// SetWithTimestamp 设置缓存，并指定最后修改时间
func (c *MemoryCache) SetWithTimestamp(key string, data []byte, ttl time.Duration, lastModified time.Time) {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    // 如果已存在，先减去旧项的大小
    if item, exists := c.items[key]; exists {
        c.currSize -= int64(item.size)
    }

    // 创建新的缓存项
    now := time.Now()
    item := &memoryCacheItem{
        data:         data,
        expiry:       now.Add(ttl),
        lastUsed:     now,
        lastModified: lastModified,
        size:         len(data),
    }

    // 检查是否需要清理空间
    if len(c.items) >= c.maxItems || c.currSize+int64(len(data)) > c.maxSize {
        c.evict()
    }

    // 存储新项
    c.items[key] = item
    c.currSize += int64(len(data))
}
```

#### 5.2.3 定期清理过期项

```go
// 清理过期项
func (c *MemoryCache) CleanExpired() {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    now := time.Now()
    for k, v := range c.items {
        if now.After(v.expiry) {
            c.currSize -= int64(v.size)
            delete(c.items, k)
        }
    }
}

// 启动定期清理
func (c *MemoryCache) StartCleanupTask() {
    ticker := time.NewTicker(5 * time.Minute)
    go func() {
        for range ticker.C {
            c.CleanExpired()
        }
    }()
}
```

### 5.3 分片磁盘缓存实现

#### 5.3.1 分片选择

```go
// 获取键对应的分片
func (c *ShardedDiskCache) getShard(key string) *DiskCache {
    // 计算哈希值决定分片
    h := fnv.New32a()
    h.Write([]byte(key))
    shardIndex := int(h.Sum32()) % c.shardCount
    return c.shards[shardIndex]
}
```

#### 5.3.2 分片操作代理

```go
// Set 设置缓存
func (c *ShardedDiskCache) Set(key string, data []byte, ttl time.Duration) error {
    shard := c.getShard(key)
    return shard.Set(key, data, ttl)
}

// Get 获取缓存
func (c *ShardedDiskCache) Get(key string) ([]byte, bool, error) {
    shard := c.getShard(key)
    return shard.Get(key)
}

// Delete 删除缓存
func (c *ShardedDiskCache) Delete(key string) error {
    shard := c.getShard(key)
    return shard.Delete(key)
}
``` 

## 6. 性能优化

### 6.1 内存优化

#### 6.1.1 对象池

对象池是一种重用对象的技术，可以减少内存分配和垃圾回收的压力。PanSou在序列化操作中使用对象池优化性能：

```go
// GobSerializer 使用gob进行序列化/反序列化
type GobSerializer struct {
    bufferPool sync.Pool
}

// NewGobSerializer 创建新的Gob序列化器
func NewGobSerializer() *GobSerializer {
    return &GobSerializer{
        bufferPool: sync.Pool{
            New: func() interface{} {
                return new(bytes.Buffer)
            },
        },
    }
}

// Serialize 序列化
func (s *GobSerializer) Serialize(v interface{}) ([]byte, error) {
    buf := s.bufferPool.Get().(*bytes.Buffer)
    buf.Reset()
    defer s.bufferPool.Put(buf)
    
    // 使用缓冲区进行序列化
    enc := gob.NewEncoder(buf)
    if err := enc.Encode(v); err != nil {
        return nil, err
    }
    
    // 复制缓冲区数据，因为buf会被重用
    data := make([]byte, buf.Len())
    copy(data, buf.Bytes())
    
    return data, nil
}
```

这种优化减少了每次序列化操作时创建新缓冲区的开销，特别是在高并发场景下，可以显著降低GC压力。

#### 6.1.2 预分配容量

PanSou在创建map、slice等数据结构时，会预先分配合适的容量，避免动态扩容带来的性能损失：

```go
// 预估合并后的结果数量
totalSize := len(tgResults) + len(pluginResults)
if totalSize == 0 {
    return []model.SearchResult{}
}

// 创建结果映射，用于去重，预分配容量
resultMap := make(map[string]model.SearchResult, totalSize)
```

#### 6.1.3 零拷贝技术

在某些场景下，PanSou使用零拷贝技术避免不必要的内存拷贝：

```go
// 使用指针传递大型数据结构
func (c *EnhancedTwoLevelCache) GetSerializer() Serializer {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    return c.serializer
}
```

### 6.2 并发优化

#### 6.2.1 分片锁

PanSou使用分片锁技术减少锁竞争，提高并发性能。每个分片有自己的锁，不同分片的操作可以并行执行，减少了锁竞争。

#### 6.2.2 读写锁

PanSou在缓存操作中使用读写锁，允许多个读操作并发执行：

```go
// Get 获取缓存
func (c *MemoryCache) Get(key string) ([]byte, bool) {
    c.mutex.RLock()  // 使用读锁
    item, exists := c.items[key]
    c.mutex.RUnlock()
    
    if !exists {
        return nil, false
    }
    
    // 检查是否过期
    if time.Now().After(item.expiry) {
        c.mutex.Lock()  // 使用写锁
        delete(c.items, key)
        c.currSize -= int64(item.size)
        c.mutex.Unlock()
        return nil, false
    }
    
    // 更新最后使用时间
    c.mutex.Lock()
    item.lastUsed = time.Now()
    c.mutex.Unlock()
    
    return item.data, true
}
```

#### 6.2.3 异步写入

PanSou使用异步写入策略，避免磁盘I/O操作阻塞主流程，提高了系统的响应速度。

### 6.3 I/O优化

#### 6.3.1 批量操作

PanSou在适当的场景下使用批量操作，减少系统调用的次数：

```go
// 批量执行搜索任务
results := pool.ExecuteBatchWithTimeout(tasks, concurrency, config.AppConfig.PluginTimeout)
```

#### 6.3.2 延迟写入

PanSou使用延迟写入策略，减少磁盘写入次数：

```go
// 启动定期保存缓存到磁盘的goroutine
func startCachePersistence() {
    // 每2分钟保存一次缓存
    ticker := time.NewTicker(cacheSaveInterval)
    defer ticker.Stop()
    
    for range ticker.C {
        // 检查是否有缓存项需要保存
        if hasCacheItems() {
            saveCacheToDisk()
        }
    }
}
```

#### 6.3.3 文件系统优化

PanSou通过分片存储和合理的文件命名策略，优化了文件系统的性能：

```go
// 获取文件名
func (c *DiskCache) getFilename(key string) string {
    hash := md5.Sum([]byte(key))
    return hex.EncodeToString(hash[:])
}
```

### 6.4 性能指标

在实际应用中，PanSou缓存系统展现出了卓越的性能：

| 指标 | 数值 | 说明 |
|------|------|------|
| 缓存命中率 | >95% | 大部分请求可以直接从缓存获取结果 |
| 内存缓存访问时间 | <1ms | 内存缓存提供极速访问 |
| 磁盘缓存访问时间 | <10ms | 分片磁盘缓存提供快速访问 |
| 缓存写入时间 | <5ms | 异步写入策略提高写入性能 |
| 并发处理能力 | >1000 QPS | 系统可以处理高并发请求 |

## 7. 多次搜索流程

### 7.1 首次搜索（缓存未命中）

当用户首次执行搜索时，系统会经历以下步骤：

```
┌─────────────────────────┐
│     用户搜索请求          │
│   (关键词："电影")        │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     生成缓存键           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  检查内存缓存（未命中）    │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  检查磁盘缓存（未命中）    │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     并行执行搜索          │
│  (TG搜索 + 插件搜索)      │
└───────────┬─────────────┘
            │
┌───────────┬─────────────┐
│ 常规插件   │   异步插件   │
└─────┬─────┘┌────┬───────┘
      │      │    │
      │      │    │ 响应超时
      │      │    ▼
      │      │┌──────────┐
      │      ││ 返回部分  │
      │      ││ 结果或空  │
      │      │└────┬─────┘
      │      │     │ 后台继续处理
      │      │     ▼
      │      │┌──────────┐
      │      ││ 完成搜索  │
      │      │└────┬─────┘
      │      │     │
      │      ▼     ▼
┌─────▼────────────────────┐
│      合并所有结果          │
└───────────┬──────────────┘
            │
┌───────────▼──────────────┐
│   过滤和排序结果           │
└───────────┬──────────────┘
            │
┌───────────▼──────────────┐
│     更新内存缓存           │
└───────────┬──────────────┘
            │
┌───────────▼──────────────┐
│   异步更新磁盘缓存         │
└───────────┬──────────────┘
            │
┌───────────▼──────────────┐
│     返回结果给用户 (100条) │
└──────────────────────────┘
```

**详细说明：**

1. **缓存键生成**：系统根据搜索关键词和其他参数生成唯一的缓存键
   ```go
   normalizedKeyword := strings.ToLower(strings.TrimSpace(keyword))
   keyStr := fmt.Sprintf("plugin:%s:all", normalizedKeyword)
   hash := md5.Sum([]byte(keyStr))
   cacheKey := hex.EncodeToString(hash[:])
   ```

2. **缓存检查**：系统首先检查内存缓存，然后检查磁盘缓存，均未命中

3. **执行搜索**：系统并行执行TG搜索和插件搜索
   ```go
   var wg sync.WaitGroup
   wg.Add(2)
   
   go func() {
       defer wg.Done()
       tgResults, tgErr = s.searchTG(keyword, channels, forceRefresh)
   }()
   
   go func() {
       defer wg.Done()
       pluginResults, pluginErr = s.searchPlugins(keyword, plugins, forceRefresh, concurrency)
   }()
   
   wg.Wait()
   ```

4. **异步插件处理**：异步插件可能在响应超时前只返回部分结果，但会在后台继续处理
   ```go
   // 在AsyncSearch方法中的响应超时处理
   select {
   case results := <-resultChan:
       close(doneChan)
       return results, nil
   case err := <-errorChan:
       close(doneChan)
       return nil, err
   case <-time.After(responseTimeout):
       // 响应超时，返回空结果，后台继续处理
       go func() {
           defer close(doneChan)
       }()
       return []model.SearchResult{}, nil
   }
   ```

5. **结果处理**：系统合并、过滤和排序所有搜索结果

6. **缓存更新**：系统将处理后的结果异步写入内存缓存和磁盘缓存

7. **返回结果**：系统将处理后的结果返回给用户

### 7.2 第二次搜索（短时间内，内存缓存命中）

当用户在短时间内再次执行相同搜索时，系统会经历以下步骤：

```
┌─────────────────────────┐
│     用户搜索请求          │
│   (关键词："电影")        │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     生成缓存键           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  检查内存缓存（命中）      │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     返回缓存结果 （150条） │
└─────────────────────────┘
```

**详细说明：**

1. **缓存键生成**：与首次搜索相同，系统生成唯一的缓存键

2. **内存缓存命中**：系统检查内存缓存，发现命中。此时异步插件在陆续后台更新缓存，可能还没更新完毕。
   ```go
   data, _, memHit := c.memory.GetWithTimestamp(key)
   if memHit {
       return data, true, nil
   }
   ```

3. **返回缓存结果**：系统直接返回缓存结果，无需执行搜索

### 7.3 第三次搜索（异步插件已更新缓存）

当异步插件在后台完成处理并更新了缓存后，用户再次执行相同搜索时，系统会经历以下步骤：

```
┌─────────────────────────┐
│     用户搜索请求          │
│   (关键词："电影")        │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     生成缓存键           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  检查内存缓存（命中）      │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│    返回更新后的结果 (500条)│
└─────────────────────────┘
```

**详细说明：**

1. **缓存键生成**：与之前相同，系统生成唯一的缓存键

2. **内存缓存命中**：系统检查内存缓存，发现命中。假设此时异步插件各自的插件缓存都更新完毕了，插件会主动更新主缓存，所以此时内存中的缓存数据也被更新过了

5. **返回结果**：系统返回更新后的结果

## 8. 异步插件与主缓存协同

### 8.1 主缓存注入

系统在初始化时将主缓存系统注入到异步插件中，实现统一的缓存更新：

```go
// injectMainCacheToAsyncPlugins 将主缓存系统注入到异步插件中
func injectMainCacheToAsyncPlugins(pluginManager *plugin.PluginManager, mainCache *cache.EnhancedTwoLevelCache) {
    // 创建缓存更新函数
    cacheUpdater := func(key string, data []byte, ttl time.Duration) error {
        return mainCache.Set(key, data, ttl)
    }
    
    // 注入到所有异步插件
    for _, p := range pluginManager.GetPlugins() {
        if asyncPlugin, ok := p.(interface{ SetMainCacheUpdater(func(string, []byte, time.Duration) error) }); ok {
            asyncPlugin.SetMainCacheUpdater(cacheUpdater)
        }
    }
}
```

### 8.2 缓存键一致性

为了确保异步插件和主缓存系统使用相同的缓存键，系统实现了缓存键传递机制：

```go
// BaseAsyncPlugin 基础异步插件结构
type BaseAsyncPlugin struct {
    name              string                                    // 插件名称
    priority          int                                       // 优先级
    client            *http.Client                              // 短超时客户端
    backgroundClient  *http.Client                              // 长超时客户端
    cacheTTL          time.Duration                             // 缓存有效期
    mainCacheUpdater  func(string, []byte, time.Duration) error // 主缓存更新函数
    MainCacheKey      string                                    // 主缓存键，导出字段，由主程序设置
}

// SetMainCacheKey 设置主缓存键
func (p *BaseAsyncPlugin) SetMainCacheKey(key string) {
    p.MainCacheKey = key
}
```

### 8.3 异步更新机制

异步插件实现了"尽快响应，持续处理"的异步模式，在后台完成搜索后更新缓存：

```go
// 在后台完成搜索并更新缓存
func (p *BaseAsyncPlugin) completeSearchInBackground(keyword string, searchFunc func(string) ([]model.SearchResult, error), cachedResponse *cachedResponse, pluginSpecificCacheKey, mainCacheKey string, doneChan chan struct{}) {
    defer func() {
        select {
        case <-doneChan:
            // 已经关闭，无需操作
        default:
            close(doneChan)
        }
    }()

    // 执行完整搜索
    results, err := searchFunc(keyword)
    if err != nil {
        return
    }

    // 更新缓存
    cachedResponse.Results = results
    cachedResponse.Complete = true
    cachedResponse.Timestamp = time.Now()

    // 序列化缓存数据
    data, err := json.Marshal(cachedResponse)
    if err != nil {
        return
    }

    // 更新插件特定缓存
    p.setPluginCache(pluginSpecificCacheKey, data)

    // 如果提供了主缓存键和更新函数，更新主缓存
    if mainCacheKey != "" && p.mainCacheUpdater != nil {
        p.mainCacheUpdater(mainCacheKey, data, p.cacheTTL)
    }
}
``` 

## 9. 总结

PanSou缓存系统是一套精心设计的多层次缓存解决方案，通过增强版两级缓存（内存+分片磁盘）和异步插件缓存系统的协同工作，实现了高性能、高可用的搜索体验。

### 9.1 关键特性

1. **增强版两级缓存**：结合内存缓存和分片磁盘缓存的优势，提供快速访问和持久存储
2. **分片磁盘缓存**：通过分片减少锁竞争，提高并发性能
3. **异步写入机制**：缓存写入异步执行，不阻塞主流程
4. **智能缓存管理**：基于访问频率、时间和热度的缓存淘汰策略
5. **异步插件缓存系统**：实现"尽快响应，持续处理"的异步模式


### 9.2 性能优化亮点

1. **对象池**：重用对象，减少内存分配和垃圾回收压力
2. **预分配容量**：避免动态扩容带来的性能损失
3. **零拷贝技术**：避免不必要的内存拷贝
4. **分片锁**：减少锁竞争，提高并发性能
5. **读写锁**：允许多个读操作并发执行
6. **异步写入**：避免磁盘I/O操作阻塞主流程
7. **批量操作**：减少系统调用的次数
8. **延迟写入**：减少磁盘写入次数
9. **文件系统优化**：通过分片存储和合理的文件命名策略，优化文件系统性能
